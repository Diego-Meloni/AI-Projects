{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2/09/2025 Deep Learning exam implementation\n",
        "## Diego Meloni 536041"
      ],
      "metadata": {
        "id": "tMnNzpkZA6DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Architecture choice\n",
        "I chose a Hopfield Network as a local optimizer to solve the given task, since the problem is structured as a graph where nodes only have partial labeling, but do not contain any additional features or information. If nodes had features, an architecture such as a Graph Convolutional Network would have been more appropriate.\n",
        "A regular MLP (Multi layer perceptron) would not be a good architecture choice since it would not be able to exploit nodes similarity.\n",
        "\n",
        "The implementation matches the solution I provided in the exam, so no CHANGE blocks were required.\n"
      ],
      "metadata": {
        "id": "mX2alsozvpBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook setup and data download\n",
        "Here I download the dataset and setup the notebook."
      ],
      "metadata": {
        "id": "44-AW87UBsN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Dataset parts\n",
        "parts = [\n",
        "    \"https://github.com/Diego-Meloni/AI-Projects/raw/refs/heads/main/Hopfield%20Network/input_data_part01.pkl\",\n",
        "    \"https://github.com/Diego-Meloni/AI-Projects/raw/refs/heads/main/Hopfield%20Network/input_data_part02.pkl\",\n",
        "    \"https://github.com/Diego-Meloni/AI-Projects/raw/refs/heads/main/Hopfield%20Network/input_data_part03.pkl\",\n",
        "    \"https://github.com/Diego-Meloni/AI-Projects/raw/refs/heads/main/Hopfield%20Network/input_data_part04.pkl\",\n",
        "    \"https://github.com/Diego-Meloni/AI-Projects/raw/refs/heads/main/Hopfield%20Network/input_data_part05.pkl\"\n",
        "]\n",
        "\n",
        "output_file = \"input_data.pkl\"\n",
        "\n",
        "# Function to download the dataset (first time only)\n",
        "if not os.path.exists(output_file):\n",
        "    with open(output_file, \"wb\") as f_out:\n",
        "        for idx, url in enumerate(parts):\n",
        "            print(f\"Downloading part {idx+1}...\")\n",
        "            r = requests.get(url)\n",
        "            r.raise_for_status()\n",
        "            f_out.write(r.content)\n",
        "    print(\"Download completed.\")\n",
        "\n",
        "else:\n",
        "    print(\"File already present, download skipped.\")\n",
        "\n",
        "# Load the dataset\n",
        "with open(output_file, \"rb\") as f:\n",
        "    data_dict = pk.load(f)\n",
        "\n",
        "# Weight matrix, initial labels and true labels are provided\n",
        "W = data_dict['similarity_matrix']\n",
        "labels = data_dict['labels']\n",
        "true_labels = data_dict['true_labels']\n",
        "\n",
        "# Check if shapes are correct\n",
        "print(f\"\\nWeight matrix shape: {W.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"True labels shape: {true_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qhJ-3aPA5Mk",
        "outputId": "3993e316-7d8d-4721-b942-833f9d1039d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading part 1...\n",
            "Downloading part 2...\n",
            "Downloading part 3...\n",
            "Downloading part 4...\n",
            "Downloading part 5...\n",
            "Download completed.\n",
            "\n",
            "Weight matrix shape: (5000, 5000)\n",
            "Labels shape: (5000,)\n",
            "True labels shape: (5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Preprocessing\n",
        "I considered two possible preprocessing steps:\n",
        "- Mapping string labels into numeric values {1, 0, -1}. (In this dataset the labels were already numeric, but I implemented a custom function to handle the string case if needed.)\n",
        "- Setting the diagonal of the weight matrix to 0, in order to prevent self-connections between neurons.\n"
      ],
      "metadata": {
        "id": "OGatAWX5hEXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Maps the input labels to {-1, 0, 1} values or returns an error.\n",
        "def preprocess_labels(labels):\n",
        "    # Case 1: labels are strings\n",
        "    if isinstance(labels[0], str):\n",
        "        new_labels = []\n",
        "        for l in labels:\n",
        "            if l == \"Database\":\n",
        "                new_labels.append(1)\n",
        "            elif l == \"Unknown\":\n",
        "                new_labels.append(0)\n",
        "            else:\n",
        "                new_labels.append(-1)\n",
        "        return np.array(new_labels)\n",
        "\n",
        "    # Case 2: labels are numbers\n",
        "    elif isinstance(labels[0], (int, float, np.int64)):\n",
        "        ok_values = [-1, 0, 1]\n",
        "        if all(l in ok_values for l in labels):\n",
        "            return labels.astype(int)\n",
        "        else:\n",
        "            print(\"Input format incorrect: numeric values not in {-1,0,1}\")\n",
        "            return None\n",
        "\n",
        "    # Case 3: wrong type\n",
        "    else:\n",
        "        print(\"Input format incorrect: labels must be strings or {-1,0,1}\")"
      ],
      "metadata": {
        "id": "FL80zzjNuZj9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing steps\n",
        "labels = preprocess_labels(labels) # Maps the input labels to {-1, 0, 1} values if needed.\n",
        "np.fill_diagonal(W, 0)  # Removes eventual self-connections in the neurons."
      ],
      "metadata": {
        "id": "_Mfs-eomw4L9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3a, 3b, 3c: Implementation of the Hopfield Network as Local Optimizer\n",
        "In line with my exam solution, my implementation takes as input:\n",
        "- The number of neurons of the Hopfield Network (size).\n",
        "- The weight matrix.\n",
        "- The partial labels of the neurons.\n",
        "- The maximum number of iterations (default value set to 100, but modifiable at call time).\n",
        "\n",
        "The model separates the neurons into two categories:\n",
        "- **Fixed neurons**: initially labeled with +1 or -1. They are not updated during the dynamics, but their influence contributes to the updates of the initially unlabeled neurons.\n",
        "- **Free neurons**: initially labeled with 0. Their states are updated asynchronously, meaning neuron **i** is updated using the most recent values of neurons 0 → i-1 and the old values of neurons i+1 → n. Each update considers the influence of fixed neurons (bias) and the weighted input from other neurons.\n",
        "\n",
        "The model stops either when it reaches the maximum number of iterations, or when it reaches an equilibrium state (no updates occur running the dynamic).\n"
      ],
      "metadata": {
        "id": "ZdcGC-uvcdwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOTE\n",
        "The implementation follows my exam solution exactly. I chose to **add** the bias rather than subtract it, because we want to add the influence of the fixed neurons instead of subtracting it.\n",
        "\n",
        "Since the bias can take both positive and negative values, it still behaves as a threshold. I have also noticed the dynamics are more effective when the bias is added, leading to better and more consistent results (also confirmed by additional tests I carried out separately)."
      ],
      "metadata": {
        "id": "89Vl6mCAkyMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3e: Hyperparameter tuning and selection\n",
        "The model has only two hyperparameters:\n",
        "- The number of neurons\n",
        "- The maximum number of epochs\n",
        "\n",
        "As stated in the exam, hyperparameter tuning is not required in this case. The number of neurons is fixed by the graph structure, and the dynamics usually converge in just a few iterations, making epoch tuning unnecessary.\n",
        "\n",
        "I implemented two stopping conditions: one when an equilibrium state is reached (no neuron is updated), and one when the maximum number of epochs is reached.\n"
      ],
      "metadata": {
        "id": "865_wx-TkPzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Hopfield network as local optimizer\n",
        "class HopfieldNetworkLO:\n",
        "    def __init__(self, size,  weight_matrix, labels, max_iterations=100):\n",
        "        \"\"\"Initialize network with a given weight matrix.\"\"\"\n",
        "        self.W = np.array(weight_matrix)  # Convert weight matrix to numpy array\n",
        "        self.N = self.W.shape[0]  # Number of neurons\n",
        "        # Checks if the declared number of neurons is coherent with Weight matrix dimension\n",
        "        if self.N != size:\n",
        "          print('Declared number of neurons and Weight matrix shape not corresponding')\n",
        "        self.max_iterations = max_iterations\n",
        "\n",
        "        \"\"\" Divide the neurons in 2 categories based on their initial label\"\"\"\n",
        "        self.state = np.array(labels, dtype=int)  # Convert labels to an integers array\n",
        "        self.free_neurons = np.where(self.state == 0)[0]  # Indices of neurons to update\n",
        "        self.fixed_neurons = np.where(self.state != 0)[0]  # Indices of fixed neurons\n",
        "\n",
        "    @property # To call the method without () since there are no parameters.\n",
        "    def run_dynamics(self):\n",
        "        \"\"\"Perform asynchronous updates for neurons labeled as '0'.\"\"\"\n",
        "        # Compute external influence from fixed neurons\n",
        "        b = np.dot(self.W[:, self.fixed_neurons], self.state[self.fixed_neurons])  # Activation threshold\n",
        "        e = 0 # Counter for epochs\n",
        "\n",
        "        for e in range(self.max_iterations):\n",
        "            e += 1\n",
        "            updated = False\n",
        "            for i in self.free_neurons:\n",
        "                # Compute total input sum (including fixed neurons' influence)\n",
        "                activation = np.dot(self.W[i], self.state) + b[i]\n",
        "                new_state = 1 if activation >= 0 else -1\n",
        "\n",
        "                if new_state != self.state[i]:\n",
        "                    self.state[i] = new_state\n",
        "                    updated = True\n",
        "\n",
        "            # Stop if no changes occur (equilibrium state)\n",
        "            if not updated:\n",
        "                print(f\"Number of epochs: {e}\")\n",
        "                return self.state\n",
        "\n",
        "        # Stop if the maximum number of epochs is reached\n",
        "        print(\"Maximum number of epochs reached\")\n",
        "        return self.state"
      ],
      "metadata": {
        "id": "QL_9pwGFKFgY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Evaluation function\n",
        "I created a function which evaluates the reconstruction accuracy of the initially unlabeled neurons.\n",
        "\n",
        "It takes as input the initial partial labels, our prediction, and the true labels, and returns:\n",
        "- The accuracy of the model (correct predictions/total predictions).\n",
        "- The list of predictions.\n",
        "- The list of true labels corresponding to the prediction.\n",
        "- The position of the unknown neurons in the original labels."
      ],
      "metadata": {
        "id": "yCAFmOXpm9mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute accuracy only on the unknown (0-labelled) authors\n",
        "def evaluate_accuracy_on_unknowns(initial_labels, inferred_labels, true_labels):\n",
        "    # Find indices of neurons that were initially unknown\n",
        "    unknown_indices = np.where(initial_labels == 0)[0]\n",
        "\n",
        "    # Predicted vs true for only these indices\n",
        "    preds = inferred_labels[unknown_indices]\n",
        "    trues = true_labels[unknown_indices]\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = np.mean(preds == trues)\n",
        "    print(f\"\\nAccuracy on unknown (0-labelled) nodes: {accuracy}\")\n",
        "    return accuracy, preds, trues, unknown_indices"
      ],
      "metadata": {
        "id": "QarvXjUD22a7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "I instantiated the Hopfield Network and applied it to the input graph in order to update the labels of the unknown authors (initial label = 0). The model’s performance is then evaluated by measuring its accuracy.  \n",
        "\n",
        "For clarity, I also included visualizations of both the dataset and the predictions, together with a sample of the reconstructed labels produced by the dynamics.\n"
      ],
      "metadata": {
        "id": "yE_Av7ehKuvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and update the network\n",
        "size = int(labels.shape[0]) # Number of neurons of the Network\n",
        "hopfield_net = HopfieldNetworkLO(size, W, labels)\n",
        "inferred_state = hopfield_net.run_dynamics\n",
        "\n",
        "# Visualize our original dataset, the predictions and the true labels\n",
        "print(f\"\\nOriginal labels: {labels}\")\n",
        "print(f\"Inferred labels: {inferred_state}\")\n",
        "print(f\"True labels:     {true_labels}\")\n",
        "\n",
        "# Evaluate\n",
        "acc, preds, trues, unknown_indices = evaluate_accuracy_on_unknowns(labels, inferred_state, true_labels)\n",
        "print(f\"Number of predictions: {int(preds.shape[0])}\")\n",
        "\n",
        "# Print first 20 unknowns with predicted vs true\n",
        "print(\"\\nFirst 20 predictions for initially unknown authors:\")\n",
        "for i in range(min(20, len(unknown_indices))):\n",
        "    idx = unknown_indices[i]\n",
        "    print(f\"  Author {idx+1}: predicted= {preds[i]}, true= {trues[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIBYVJTRKvs1",
        "outputId": "4d956822-48ab-4122-ae8b-9ec8a32a9225"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epochs: 3\n",
            "\n",
            "Original labels: [-1  0  1 ...  1 -1 -1]\n",
            "Inferred labels: [-1 -1  1 ...  1 -1 -1]\n",
            "True labels:     [-1 -1  1 ...  1 -1 -1]\n",
            "\n",
            "Accuracy on unknown (0-labelled) nodes: 0.7986666666666666\n",
            "Number of predictions: 750\n",
            "\n",
            "First 20 predictions for initially unknown authors:\n",
            "  Author 2: predicted= -1, true= -1\n",
            "  Author 8: predicted= -1, true= -1\n",
            "  Author 16: predicted= 1, true= 1\n",
            "  Author 32: predicted= -1, true= -1\n",
            "  Author 38: predicted= -1, true= -1\n",
            "  Author 44: predicted= -1, true= -1\n",
            "  Author 55: predicted= 1, true= 1\n",
            "  Author 65: predicted= -1, true= -1\n",
            "  Author 67: predicted= -1, true= -1\n",
            "  Author 82: predicted= 1, true= 1\n",
            "  Author 84: predicted= -1, true= 1\n",
            "  Author 89: predicted= -1, true= -1\n",
            "  Author 95: predicted= -1, true= -1\n",
            "  Author 102: predicted= 1, true= 1\n",
            "  Author 120: predicted= 1, true= -1\n",
            "  Author 145: predicted= 1, true= 1\n",
            "  Author 170: predicted= -1, true= -1\n",
            "  Author 173: predicted= -1, true= -1\n",
            "  Author 179: predicted= -1, true= -1\n",
            "  Author 182: predicted= 1, true= 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block displays the confusion matrix.\n",
        "\n",
        "The results show a fairly balanced matrix, moreover the model has a good performance on the predicted labels meaning it managed to effectively leverage the similarity of the authors.\n",
        "This confirms Hopflied Network as Local Optimizer was a good architecture choice for our task."
      ],
      "metadata": {
        "id": "I5ktoiBqbpZR"
      }
    }
  ]
}